{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mijanr/TimeSeries/blob/master/Ford_data_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Ghl6lhbFAPAM"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "#tensorboard\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "writer = SummaryWriter('runs/ford_data_classification')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "rOhKyWuyAPAQ"
      },
      "outputs": [],
      "source": [
        "root_url = \"https://raw.githubusercontent.com/hfawaz/cd-diagram/master/FordA/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "qlxUatu9APAR"
      },
      "outputs": [],
      "source": [
        "def readucr(filename):\n",
        "    data = np.loadtxt(filename, delimiter=\"\\t\")\n",
        "    y = data[:, 0]\n",
        "    x = data[:, 1:]\n",
        "    return x, y.astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "JaMO0eMIAPAR"
      },
      "outputs": [],
      "source": [
        "x_train, y_train = readucr(root_url + \"FordA_TRAIN.tsv\")\n",
        "x_test, y_test = readucr(root_url + \"FordA_TEST.tsv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "45fhd9KkAPAS"
      },
      "outputs": [],
      "source": [
        "#convert y to 0 and 1\n",
        "y_train[y_train == -1] = 0\n",
        "y_test[y_test == -1] = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "s_4bqc3gAPAS"
      },
      "outputs": [],
      "source": [
        "#normalize x\n",
        "x_train = MinMaxScaler().fit_transform(x_train)\n",
        "x_test = MinMaxScaler().fit_transform(x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "znjC5BePAPAS"
      },
      "outputs": [],
      "source": [
        "#expand dimension\n",
        "x_train = np.expand_dims(x_train, axis=1)\n",
        "x_test = np.expand_dims(x_test, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P_Hhh6VhAPAT",
        "outputId": "84bd8b24-8f60-4b17-a084-be3f947ae478"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(3601, 1, 500) (3601,) (1320, 1, 500) (1320,)\n"
          ]
        }
      ],
      "source": [
        "#check shapes\n",
        "print(x_train.shape, y_train.shape, x_test.shape, y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "PkeLUuv7APAU"
      },
      "outputs": [],
      "source": [
        "#convert to torch tensors\n",
        "x_train = torch.from_numpy(x_train).float()\n",
        "y_train = torch.from_numpy(y_train).long()\n",
        "x_test = torch.from_numpy(x_test).float()\n",
        "y_test = torch.from_numpy(y_test).long()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "5vdhvtvZAPAU"
      },
      "outputs": [],
      "source": [
        "#convert to torch dataset\n",
        "train = TensorDataset(x_train, y_train)\n",
        "test = TensorDataset(x_test, y_test)\n",
        "#convert to dataloader\n",
        "train_loader = DataLoader(train, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test, batch_size=64, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oMX9lXUbAPAV",
        "outputId": "d9756c66-caca-4862-fe9a-a768d8060ed9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([64, 1, 500]) torch.Size([64])\n"
          ]
        }
      ],
      "source": [
        "#check shapes\n",
        "for x, y in train_loader:\n",
        "    print(x.shape, y.shape)\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "5wTotBrJAPAV"
      },
      "outputs": [],
      "source": [
        "#1D CNN\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        self.sequential = nn.Sequential(\n",
        "            nn.Conv1d(1, 64, 3),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool1d(2),\n",
        "            nn.Conv1d(64, 128, 3),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool1d(2),\n",
        "            nn.Conv1d(128, 128, 3),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool1d(2),\n",
        "            #flatten\n",
        "            nn.Flatten(),\n",
        "            nn.LazyLinear(out_features=128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 2)\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.sequential(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wl_xz77ZAPAV",
        "outputId": "3c97da86-65cc-4ba3-b095-cf5380f0570a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cpu\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/pops/anaconda3/lib/python3.9/site-packages/torch/nn/modules/lazy.py:178: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
            "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "model = CNN().to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zOfcDr4TAPAW",
        "outputId": "b0026a10-2e4a-4528-b8e8-f37ca9d49699"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([64, 2])\n"
          ]
        }
      ],
      "source": [
        "#feed a sample to the model\n",
        "for x, y in train_loader:\n",
        "    x = x.to(device)\n",
        "    print(model(x).shape)\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "ObnATO41APAW"
      },
      "outputs": [],
      "source": [
        "#loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "if1o2TyWAPAW",
        "outputId": "a4a4d318-2e11-442d-d125-9a63e363a938"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 0 \tTraining Loss: 0.695103\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m/home/pops/myProjects/TimeSeries/Ford_data_classification.ipynb Cell 17\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/pops/myProjects/TimeSeries/Ford_data_classification.ipynb#X22sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_epochs):\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/pops/myProjects/TimeSeries/Ford_data_classification.ipynb#X22sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     train_loss \u001b[39m=\u001b[39m \u001b[39m0.0\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/pops/myProjects/TimeSeries/Ford_data_classification.ipynb#X22sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     \u001b[39mfor\u001b[39;00m x, y \u001b[39min\u001b[39;00m train_loader:\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/pops/myProjects/TimeSeries/Ford_data_classification.ipynb#X22sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m         x \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/pops/myProjects/TimeSeries/Ford_data_classification.ipynb#X22sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m         y \u001b[39m=\u001b[39m y\u001b[39m.\u001b[39mto(device)\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py:652\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    649\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    650\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    651\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 652\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    653\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    654\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    655\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    656\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py:692\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    691\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 692\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    693\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    694\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n\u001b[0;32m---> 52\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcollate_fn(data)\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py:172\u001b[0m, in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mall\u001b[39m(\u001b[39mlen\u001b[39m(elem) \u001b[39m==\u001b[39m elem_size \u001b[39mfor\u001b[39;00m elem \u001b[39min\u001b[39;00m it):\n\u001b[1;32m    171\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39meach element in list of batch should be of equal size\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m--> 172\u001b[0m transposed \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39;49m(\u001b[39mzip\u001b[39;49m(\u001b[39m*\u001b[39;49mbatch))  \u001b[39m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[1;32m    174\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(elem, \u001b[39mtuple\u001b[39m):\n\u001b[1;32m    175\u001b[0m     \u001b[39mreturn\u001b[39;00m [default_collate(samples) \u001b[39mfor\u001b[39;00m samples \u001b[39min\u001b[39;00m transposed]  \u001b[39m# Backwards compatibility.\u001b[39;00m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "#training\n",
        "n_epochs = 200\n",
        "for epoch in range(n_epochs):\n",
        "    train_loss = 0.0\n",
        "    for x, y in train_loader:\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(x)\n",
        "        loss = criterion(outputs, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss += loss.item() * x.size(0)\n",
        "    train_loss = train_loss / len(train_loader.dataset)\n",
        "    if epoch % 100 == 0:\n",
        "        print(\"Epoch: {} \\tTraining Loss: {:.6f}\".format(epoch, train_loss))\n",
        "    #log loss\n",
        "    writer.add_scalar(\"training loss\", train_loss, epoch)\n",
        "    #log accuracy\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for x, y in test_loader:\n",
        "            x = x.to(device)\n",
        "            y = y.to(device)\n",
        "            outputs = model(x)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += y.size(0)\n",
        "            correct += (predicted == y).sum().item()\n",
        "    accuracy = 100 * correct / total\n",
        "    writer.add_scalar(\"accuracy\", accuracy, epoch)\n",
        "    #close writer\n",
        "    writer.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WcHEFX2GAPAX",
        "outputId": "00de1634-6af4-4dd2-80b0-e5307591bc33"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 85.60606060606061 %\n"
          ]
        }
      ],
      "source": [
        "#check the mdodel on test data\n",
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for x, y in test_loader:\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "        outputs = model(x)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += y.size(0)\n",
        "        correct += (predicted == y).sum().item()\n",
        "    print(f'Accuracy: {100 * correct / total} %')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "3qOtqNokAPAX"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.9.12 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "7ab6c9a234243e9b1b8e01397e3e97ef7ba16898c560b20da106745d48591deb"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
